1) KNN
# Создание классификатора
classifierKNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
# Обучение классификатора на тренировочных данных
classifierKNN.fit(X_train.values, y_train.values)
KNeighborsClassifier()
Метрика minkowski здесь означает MinkowskiDistance, которая рассчитывается по формуле как сумма ( | x - y | ^ p) ^( 1/p )
# Применение классификации к тестовым данным.
y_pred = classifierKNN.predict(X_test.values)
# Результат предсказания покупок на тестовых данных.
y_pred
array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1], dtype=int8)
y_test.values
array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1], dtype=int8)
# Оценка результатов KNN классификации
# Смотрим матрицу ошибок.
cm1 = confusion_matrix(y_test,y_pred)
print(cm1)
  [[63  5]
  [ 2 30]]
# Она же, но графически.
sns.heatmap(cm1, annot=True, fmt='d', cmap='Spectral')
plt.show()

# значение ошибки.
np.mean(y_pred != y_test)

Выбор значения К:
error_rate = []

for i in range(1,40):
    # создание KNN классификатора с заданным значением k
    knn = KNeighborsClassifier(n_neighbors = i)
    # обучение его на тренировочных данных
    knn.fit(X_train.values, y_train.values)
    # прогноз покупок на тестовых данных
    pred_i = knn.predict(X_test.values)
    # сохранение значения ошибки
    error_rate.append(np.mean(pred_i != y_test))

2) SVM
# обучение модели
classifierLin = SVC(kernel = 'linear')
classifierLin.fit(X_train, y_train)
print(classifierLin.gamma)
print(classifierLin.C)
  scale
  1.0
# проверка на тестовых данных
y_pred_svc = classifierLin.predict(X_test)
y_pred_svc
array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int8)
# анализ результатов
# матрица ошибок
cm2 = confusion_matrix(y_test, y_pred_svc)
print(cm2)
 [[66  2]
 [10 22]]
sns.heatmap(cm2, annot=True, fmt='d', cmap='Spectral')
plt.show()

SVM с ядром RBF (Radial Basis Function)
# обучение модели
classifierrbf = SVC(kernel = 'rbf')
classifierrbf.fit(X_train, y_train)
print(classifierLin.gamma)
print(classifierLin.C)
  scale
  1.0
# проверка на тестовых данных
y_pred_rbf = classifierrbf.predict(X_test)
y_pred_rbf
array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1], dtype=int8)
# анализ результатов
# матрица ошибок
cm3 = confusion_matrix(y_test, y_pred_rbf)
print(cm3)
 [[64  4]
 [ 3 29]]
