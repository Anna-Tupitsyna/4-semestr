1) KNN - это алгоритм "обучения с учителем", использующийся в основном для классификации или регрессии. Он наиболее эффективен для классификаций, в которых алгоритм определяет к какому классификационному признаку отнести исходную точку путем определения K-ближайщих точек. KNN классифицирует точку данных, базируясь на известной классификации других точек (на базе тренировочных данных). 
KNN простой алгоритм, работающий на базе пространственной близости/расстояния и не нуждается в построении модели, поскольку он настраивает несколько параметров и делает предположения. KNN универсален, но становится медленнее по мере увеличения признаков.
2) Метод опорных векторов (SVM, Support vector machines) использует гиперплоскость, чтобы классифицировать данные по 2 классам.
Метод опорных векторов - это метод "обучения с учителем", использующий классификацию, регрессию и определение выбросов (outlier). Главное преимущество SVM заключается в том, что он эффективен в многомерном пространстве, даже когда количество выборок меньше количества измерений. Но в случаях, когда измерения превышают количество образцов, есть вероятность переобучения.
Основная цель алгоритма SVM - создать оптимальную линию или границу решения, представляющую собой гиперплоскость, которая может разделить n-мерное пространство на классы, чтобы в будущем можно было поместить новую точку данных в правильную категорию.
В отличие от других классификаторов, которые обращают внимание на все точки, этот метод сосредотачиваются только на точках, которые труднее всего классифицировать.
Гиперплоскость - это подпространство, размерность которого на единицу меньше, чем размер его окружающего пространства или пространства, окружающего объект. Если пространство трехмерно, то его гиперплоскости являются двумерными, двумерно, его гиперплоскости являются одномерными линиями, одномерное, его гиперплоскость представляет собой единственную точку.
SVM использует набор математических функций, известных как ядро, для создания границы оптимального решения, принимая данные в качестве входных. Наиболее предпочтительный вид функции ядра - это RBF. Потому что он локализован и имеет конечный отклик по всей оси абсцисс.
Если данные слишком похожи или их сложно разделить по какой-либо причине, или из-за того, что они нелинейны, тогда SVM с ядром может добавить еще одно измерение с «гиперплоскостью», которая может разделить точки данных.
Значениями ядра могут быть:
linear
poly
rbf (по умолчанию)
sigmoid
precomputed
